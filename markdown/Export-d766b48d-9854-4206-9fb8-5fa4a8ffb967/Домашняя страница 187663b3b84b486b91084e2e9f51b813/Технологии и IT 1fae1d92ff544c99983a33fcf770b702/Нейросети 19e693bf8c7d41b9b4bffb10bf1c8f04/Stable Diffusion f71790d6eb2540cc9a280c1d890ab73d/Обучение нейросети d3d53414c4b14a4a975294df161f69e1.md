# Обучение нейросети

---

<aside>
<img src="https://www.notion.so/icons/info-alternate_gray.svg" alt="https://www.notion.so/icons/info-alternate_gray.svg" width="40px" /> Для обучения нового чекпоинта (модели, checkpoint) нужно большое количество видеопамяти (8GB+) и достаточно много времени.

</aside>

# **Варианты обучения**

1. Textual Inversion (Текстовая инверсия)
2. Hypernetwork (Гиперсеть)
3. Dreambooth
4. Fine-tuneing

## **Textual Inversion**

Textual Inversion обучали с 8GB видеопамяти.

**Процесс обучения через Textual Inversion**

Процесс тренировки "текстовой инверсии" (т.е. одного объекта или стиля) занимает несколько часов. Около 3х. В это время компьютер поёт песнь кулеров. Возможно, можно ускорить, пока способ не нашёл. В процессе выплёвываются промежуточные результаты, по которым можно посмотреть, а что, вообще происходит.

Необходимо минимум 3-5 фоток с разных сторон одного и того же объекта. Но можно накидать намного больше в надежде, что лучше "поймёт" задачу. Потом он их будет жевать несколько часов и может быть сделает правильные выводы по поводу того, как это рисовать. Видел народ использовал до сотни фотографий, но результат не всегда получается хороший.

Где-то за пару тысяч итераций (итерация - один просмотр одной из тестовых картинок. Полный цикл тренировки - 20-30 тысяч, хотя можно и меньше), сеть находит приемлемый вариант, а потом бултыхается и не может её улучшить.

<aside>
<img src="https://www.notion.so/icons/info-alternate_gray.svg" alt="https://www.notion.so/icons/info-alternate_gray.svg" width="40px" /> **Информация:** В результате обучения формируется файл в формате .pt который необходимо переместить в /embeddings для использования в запросах. Например, `<запрос> pallas_cat`, если файл назывался **pallas_cat.pt**.

</aside>

**Пример обучения Textual Inversion**

№1 - 250 итераций.

№2 - 1250

№3 - 3500

Всего заложено 30000. (итерация - один "взгляд" на картинку чтобы что-то выучить).

## **Hypernetwork**

Предположительно можно обучить с 8GB видеопамяти.

**Гайды по обучению с использованием Hypernetwork:**

1. Гайд по обучению с использованием Hypernetwork ([Ссылка](https://rentry.org/hypernetwork4dumdums))
2. Небольшой гайд по обучению с использованием Hypernetwork ([Ссылка](https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/2670))

## **Dreambooth**

Dreambooth больше нацелен на дообучение существующей модели на новом наборе данных.

Dreambooth  обучали с 10-12GB видеопамяти или очень медленно на CPU.

[NEW Dreambooth in Automatic1111. JUST RELEASED! cpu only option.](https://www.youtube.com/watch?v=_GmGnMO8aGs)

Инструкция по обучению модели

[Dreambooth Stable Diffusion training in just 12.5 GB VRAM, using the 8bit adam optimizer from bitsandbytes along with xformers while being 2 times faster.](https://www.reddit.com/r/StableDiffusion/comments/xphaiw/dreambooth_stable_diffusion_training_in_just_125/)

[DreamBooth Stable Diffusion training in 10 GB VRAM, using xformers, 8bit adam, gradient checkpointing and caching latents.](https://www.reddit.com/r/StableDiffusion/comments/xtc25y/dreambooth_stable_diffusion_training_in_10_gb/)

## Fine-tuneing

[https://github.com/victorchall/EveryDream-trainer](https://github.com/victorchall/EveryDream-trainer)

[How to fine tune stable diffusion: how we made the text-to-pokemon model at Lambda](https://lambdalabs.com/blog/how-to-fine-tune-stable-diffusion-how-we-made-the-text-to-pokemon-model-at-lambda)

## Снижение времени и требований обучения

[Almost 7X Cheaper! Colossal-AI's Open Source Solution Accelerates AIGC at a Low-Cost Diffusion Pretraining and Hardware Fine-Tuning Can Be | Synced](https://syncedreview.com/2022/11/09/almost-7x-cheaper-colossal-ais-open-source-solution-accelerates-aigc-at-a-low-cost-diffusion-pretraining-and-hardware-fine-tuning-can-be/)

[GitHub - hpcaitech/ColossalAI: Colossal-AI: A Unified Deep Learning System for Big Model Era](https://github.com/hpcaitech/ColossalAI#Colossal-AI-in-the-Real-World)

## Полезные ссылки

[AI Art of Me - Textual Inversion vs. Dreambooth in Stable Diffusion](https://ericri.medium.com/ai-art-of-me-textual-inversion-vs-dreambooth-in-stable-diffusion-5e54bb2b881)

[You, the Multiverse of You, and Stable Diffusion](https://ericri.medium.com/you-the-multiverse-of-you-and-stable-diffusion-93c2b8b8b3f6)